%!TEX root = /home/renaud/Documents/EPL/tfe/latex/tfe.tex
% \section{Methodology}
%-----------------------DESCRIPTION OF THE METHOD---------------------------------%
\section{Description of the method}
In order to apply a clustering algorithm on a physical advection-diffusion problem, we have to define how the problem can be considered as a graph. For the next, we consider a two-dimensional problem in the coordinate system $(y,z)$. Let us partition the domain into $\nby \times \nbz$ grid cells, and denote $N_{cell} = \nby\nbz$ the total number of grid cells. Figure~\ref{fig:box_scheme} represents an example of such a domain decomposition of the rectangular domain $[0,\,L]\times[0,\,H]$ with $\nby = 15$ and $\nbz = 10$. For any time $T$, the corresponding directed graph is build as follows: each node represents a grid cell, and the weight of the edge between nodes $i$ and $j$ is the probability $m_{i,j}(T)$ that a particle ends up in grid cell $j$ after a time $T$ if it was initially in grid cell $i$. If $m_{i,j}(T) = 0$, one can equivalently consider that there is no edge between nodes $i$ and $j$. We restrict ourselves to stationary velocity field and diffusivity tensor, hence $m_{i,j}(T)$ depends only on the elapsed time $T$, not on the initial time. Hence, the initial time can indifferently be considered as being zero. The adjacency matrix $\b M(T)$ of the graph is build from the weights $m_{i,j}(T)$: $[\b M(T)]_{i,j} = m_{i,j}(T)$. It is thus precisely the transition probability matrix introduced in chapter~\ref{chap:clustering} which is needed to apply the stability clustering method. Since we consider passive tracer's particles in a domain with no-through boundary condition, we have that for any time $T$, $\b M(T)\b 1 = \b 1$, where $\b 1$ is the $N_{cell}$-dimensional unit column vector. The latter has a straightforward physical interpretation: every particle remains in the domain and particles are neither created nor destructed.

\begin{figure}[!htp]
	\centering
	\input{fig/clusters/box_scheme}
	\caption{Illustration of the decomposition of the domain into grid cells with $\nby = 15$ and $\nbz = 10$.}
	\label{fig:box_scheme}
\end{figure}

To estimate the probabilities $m_{i,j}(T)$, a Lagrangian simulation is run for a time $T$ with each grid cell containing initially $P_0$ uniformly distributed particles. Let $P_{i \rightarrow j}(T)$ denote the number of particles in grid cell $j$ at time $T$, which were initially in grid cell $i$. Using that notation, $m_{i,j}(T)$ is then numerically estimated as 
\begin{equation}
	m_{i,j}(T) = \frac{P_{i \rightarrow j}(T)}{P_0},
\end{equation}
i.e. the number of particles having started in grid cell $i$ and ending up in grid cell $j$ after time $T$, divided by $P_0$. This is exactly the \textit{box counting} method introduced in section~\ref{boxcounting_kernel} for the computation of the concentration, but instead of dividing the tracer's mass in a grid cell by the volume of that grid cell, we divide it by $P_0$. This yields an adimensional quantity that can be interpreted as a transition probability. Note that the box counting method is more adapted than a density kernel estimation for this problem because the volume average over grid cells is precisely what we want.

\section{Dealing with the time scales}
An important feature of the stability method for detecting community structures is that it is \textit{dynamic}: community structures are revealed as a function of the Markov time $t_M$. For the problems that we consider, this Markov time is intrinsically linked to the physical time: for a given time $T$, suppose that the stability method is applied on the adjacency matrix $\b M(T)$. In the discrete framework, a particle jumps from one node to another at every integer Markov time, and in the continuous framework, the expected time between jumps is $\langle \langle \b q \rangle/\b q \rangle = 1$ (cfr. page \pageref{expectedtimebetweenjumps}). Hence, a Markov time step of $1$ corresponds to a physical time step of $T$.

From the above discussion, two possibilities arise for dealing with the time scales: either we compute the adjacency matrix at one unique time $T$ and then compute the stability on the desired range of Markov times, or we compute the adjacency matrix at different times and then compute the stability on each adjacency matrix but for the Markov time $t_M = 1$ only. The advantage of the first method is that we do not have to fix \textit{a priori} the time scales at which we compute clusterings: such times scales arise naturally as plateaux in the community curve, with a low corresponding variation of information. Hence the relevant time scales are deduced from the stability curve as being the ones at which robust clusterings arise. At the contrary, the second method imposes that we choose the time scales beforehand; doing so, we lose one of the most appealing features of the stability approach. Furthermore, the first method is computationally lest costly. Even for a relatively coarse partitioning of the domain, say of about $300$ grid cells, if we release $10\,000$ particles in each grid cell there is a total of $3\e{6}$ trajectories to simulate. For long $T$, the simulation time might become restrictive, especially in the case where one does not have access to supercomputers to run the code in parallel. The same situation leads to a $300$ nodes network, which is a relatively small network size that can easily be handled by the stability software. The first method has however one important drawback: the errors in the adjacency matrix are spread and even amplified across the Markov times. If those errors become too important, the community structures found at large Markov times might become irrelevant. In other words, simulating the transition probability matrix for a time $T$ and taking the $n$th power of that matrix is not necessarily equivalent to simulating the transition probability matrix for a time $nT$. The ideal methodology is thus probably to use the first method to detect the interesting time scales and compute the corresponding community structures, and then to check that we get similar community structures at the same time scales using the second method.

%-------------------------USE OF THE TOOLBOX----------------------------%
\section{Use of the stability software}
% \newcommand\localFontSize@mlpr{10}
We present here briefly how the \textit{PartitionStability} software is used to compute the partitions. Every concept appearing here has been presented in chapter~\ref{chap:clustering}. The \mtlb{stability} function is simply called as follows : \vspace{-.2cm}
\begin{center}
	\mtlb{[S,N,VI,C] = stability(M,Markov_T,'directed','plot','teleport',tau);}
\end{center} %style = Matlab-bw for black and white
Here, \mtlb{M} is the matrix $\b M(T)$ at the desired time $T$; \mtlb{Markov_T} is the vector containing every Markov times at which the optimal stability partition has to be computed (ideally, the sampling should be exponential); the \mtlb{'directed'} option specifies that we consider a directed graph; \mtlb{'plot'} asks the program to plot the stability, number of communities and variation of information as a function of the Markov time; and \mtlb{'teleport',tau} allows to specify the value of the teleportation probability $\tau$ to \mtlb{tau}, the default value being $0.15$. In most cases, we will choose \mtlb{tau} $= 0$. This choice is motivated by the fact that if our approximation of the transition probability matrix is close enough the the exact one, then if the diffusivities are everywhere strictly positive the graph is ergodic (notice that there can be no dangling node whatever the precision of our approximation). Further in this work, one example where the graph is not ergodic will be encountered. In that case, the value of \mtlb{tau} must be chosen strictly positive in order to ensure ergodicity. A small value is then preferred, in order to minimize the impact of random teleportations on the dynamics of the graph. We will typically choose \mtlb{tau} $=10^{-3}$ in such a case.

Unfortunately, the software does not handle discrete-time stability. Instead, it allows to choose which type of laplacian should be used to calculate the (continuous-time) stability. However, the question does not arise here since both laplacians are equivalent in our case. Indeed, the total outgoing weight is the same at every node and is precisely equal to the number of particles $P_0$ released in each grid cell. Hence, $k_i = P_0$ for every node $i$ and $\langle \b k \rangle = P_0$, so that $\bs \lambda_{combi}(\b k) = \b k/ \langle \b k \rangle = \b 1 = \bs \lambda_{norm}(\b k)$. We let thus the program run with the default normalized Laplacian, since it does not make any difference in our case.

The output arguments \mtlb{S}, \mtlb{N}, \mtlb{VI} and \mtlb{C} contain respectively the stability, the number of communities, the variation of information, and the optimal partition for each Markov time contained in \mtlb{Markov_T}. If the latter is of size $n$, then \mtlb{S}, \mtlb{N} and \mtlb{VI} are $n$-dimensional vectors and \mtlb{C} is a $N_{cell} \times n$ matrix. At the $j$th Markov time, communities are labeled by consecutive integers between $0$ and \mtlb{N(j)}$-1$ such that \mtlb{C(i,j)} $= k$ means that node $i$ belongs to community $k$ at Markov time \mtlb{Markov_T(j)}.  