%!TEX root = ../tfe.tex
\chapter{Clustering}
\section{The stability criterion for graph communities} \label{sec:stability}
The partition of a graph into communities (or clusters) as been widely studies those last two decades. Clustering comes indeed pretty handy to gain insight into the underlying structure of a system represented by a network. In some casesbuild a simplified functional description based on the clusters. Many partitioning methods have been proposed, each relying on a particular measure to quantify the quality of a community structure. Such methods include normalized cut, ($\alpha$,$\epsilon$) clustering or modularity and its variants and extensions. See for instance \cite{fortunato2010community} for a 2010 survey. In this work, we choose the stability approach, which is based on the statistical properties of a dynamical process taking place on the network. This approach was initially presented in \cite{delvenne2010stability} and further expended in \cite{lambiotte2009laplacian} and \cite{delvenne2013stability}. 

The stability method presents a number of advantages. First, it does not require the number of communities to be specified beforehand, ensuring a natural partitioning of the graph. Second, it is flexible in the sense that it does not seek a \textit{unique} optimal partition. Instead, it reveals several community structures, each appearing to be the most relevant at particular values of the Markov time: at a given time scale, natural clusters corresponds to sets of states from which escape is unlikely within that time scale. The stability method provides thus a dynamical interpretation of the partitioning problem. The Markov time acts as an intrinsic resolution parameter, as will be developed shortly. Finally, it is probably the most unifying approach since many of the standard partitioning measures find an interpretation through the stability framework.

In order to compute stability partitions in the next of this work, we make use of Michael Schaub's free software \textit{PartitionStability}. This C++ implementation of the stability method with a \matlab interface is available at \url{https://github.com/michaelschaub/PartitionStability}. It relies on the Louvain algorithm \cite{blondel2008fast} to optimize the stability quality function. This heuristic algorithm has been initially developed for modularity optimisation. However one can show that stability can be written as the \textit{modularity} of a time-dependent network evolving under the Markov process \cite{lambiotte2009laplacian}. Hence, the Louvain method can almost straightforwardly be applied to stability optimisation.

This section is devoted to the explanation of the stability measure, and how to find good clusterings using stability analysis. This theoretical part is intended to cover everything that is needed to make a proper, informed use of the stability toolbox. The stability measure has initially been presented for dicrete times in \cite{delvenne2010stability}. We follow the same approach here : discrete-time stability is developed in the first part of this section; it is then extended to continuous time in a second part; finally, a few tools to analyze the robustness of a partition are presented in the third part of the section.

\subsection{Discrete-time stability as an autocovorariance}
The stability criterion is based on the two-way relationship between graphs and Markov chains: On one hand, any graph has an associated Markov chain where the states are the nodes of the graph and the transitions probabilities between states are given by the weights of the edges. On the other hand, any Markov chain can be represented by a graph whose edges are weighted according to the transition probabilities. Concretely, consider a graph of $N$ nodes whose $N \times N$ weighted adjacency matrix is denoted $\b A$. Let $\b k = \b A \b 1$; $k_i$ is thus the total weight of the outgoing edges from node $i$. Let $\b K = \mathrm{diag}(\b k)$. Then, by normalizing the rows of $\b A$ we get the matrix $\b M = \b K^{-1}\b A$, the transition probability matrix. $\b M$ is row-stochastic (or right-stochastic) and $[\b M]_{ij}$ is the probability to go from node $i$ to node $j$. 
Consider a particle moving in the network according to the transition probabilities in $\b M$. Now let $\b p_t$ be the $1 \times N$ probability vector at Markov time $t$, namely that $p_{t,i}$ is the probability that the particle is located in node $i$ at time $t$. The dynamics of the discrete-time Markov process are given by :
\begin{equation} \label{eq:discreteMP}
	\b p_{t+1} = \b p_t \b K^{-1}\b A = \b p_t \b M.  	
\end{equation} 
Now, suppose that the Markov chain is ergodic, i.e. that it is possible to go from every state to every state and that the Markov process is aperiodic. The ergodicity assumption implies that any initial state will asymptotically reach the same stationary solution. Let $\bs \pi$ be that stationary distribution, given by $\bs \pi = \bs \pi \b M$, and $\b \Pi = \rm{diag}(\bs \pi)$. Now, let $\b x_t$ be the $N$-dimensional random indicator vector describing the position of a particle undergoing the above dynamics : $x_{t,i} = 1$ if the particle is located in node $i$ at time $t$, and $0$ otherwise. At stationarity, the \textit{autocovariance matrix} of $\b x$ is
\begin{align}
 	\b C(\b x_\tau,\b x_{\tau+t}) &\triangleq \E\left[(\b x_\tau - \E[\b x_\tau])^{\t}(\b x_{\tau+t} - \E[\b x_{\tau+t}])\right] \\
 		&= \E\left[(\b x_\tau - \bs \pi)^{\t}(\b x_{\tau+t} - \bs \pi)\right] \\
 		&= \E\left[\b x_\tau^{\t} \b x_{\tau+t}\right] - \E[\b x_{\tau}^{\t}] \bs \pi - \bs \pi^{\t} \E\left[\b x_{\tau+t}\right] + \bs \pi^{\t} \bs \pi \\
 		&= \bs \Pi \b M^t - \bs \pi^{\t} \bs \pi,
 \end{align}
 where the fact that $\b C(\b x_\tau,\b x_{\tau+t})$ only depends on the time difference $t$ at stationarity is readily verified. Here, $^\t$ is the transposed sign and $\b M^t$ is $\b M$ at the power $t$. $[\b C(\b x_\tau,\b x_{\tau+t})]_{ij}$ is interpreted as the correlation between $\b x_{\tau,\,i}$ and $\b x_{\tau+t,\,j}$. The independence on the initial time $\tau$ implies that it can indifferently be chosen equal to $0$.

Suppose now a partition $\P$; we note $\b H_{\P}$ the indicator matrix of $\P$. If $c$ is the number of communities in $\P$, $\b H_{\P}$ is a binary $N \times c$ matrix such that 
\begin{equation}
	[\b H_{\P}]_{ik} = 
	\begin{cases}
		1  & \quad \mbox{if node $i$ is in community $k$},\\
	    0  & \quad \text{otherwise}.\\
	\end{cases}
\end{equation}
Let us define $\mathcal{H}_{\P} : \R[N \times N] \rightarrow \R[c \times c] : \b B \mapsto \mathcal{H}(\b B) = \b H_{\P}^{\t} \b B \b H_{\P}$. Let $\b X$ be any $N \times N$ matrix, then $\b Y = \mathcal{H}_{\P}(\b X)$ is a $c \times c$ matrix such that $[\b Y]_{kl} = \sum_{i \in \C_k,\, j \in \C_l} [\b X]_{ij}$, where $\C_k$ and $\C_l$ denote communites $k$ and $l$ of partition $\P$. One could thus say that operator $\mathcal{H}_{\P}$ returns the \textit{clustered version} of any $N \times N$ matrix, namely the matrix where the contributions of every nodes belonging to the same community are gathered by summing them. Finally, let $\b y_t = \b H_{\P}^{\t} \b x_t$ denote the $c$-dimensional community indicator vector: $\b y_{t,\,k}$ is equal to $1$ if the particle is in community $k$ at time $t$ and zero otherwise.
Using those notations and the interpretation of $\mathcal{H}_{\P} $, the \textit{clustered autocovariance matrix} for partition $\P$ at time $t$ is defined as
\begin{align}
	\b R_t(\P) &= \mathcal{H}_{\P}\left(\b C(\b x_\tau,\b x_{\tau+t})\right)\\
		&= \b C(\b y_\tau,\b y_{\tau+t})\\
		&= \b H_{\P}^{\t}(\b \Pi\b M^t - \bs \pi^{\t}\bs \pi)\b H_{\P}.
\end{align}
Notice that $\b R_t$ depends only on the topology of the graph and on the partition. If the graph has well defined communities given by $\P$ \textit{over a given time scale}, we expect that the particle is more likely to remain within the starting community overt that time scale. This implies that the values of $\b y_{0,\,i}$ and $\b y_{t,\,i}$ are positively correlated for $t$ in that time scale, which in turn implies large diagonal elements in $\b R_t(\P)$ and hence a large trace of $\b R_t(\P)$. The elements of $\b R_t(\P)$ are interpreted as follows in terms of the random walk of a particle : $[\b R_t(\P)]_{kl}$ is the probability that a particle is in community $\C_l$ after $t$ discrete time-steps if it has started in $\C_k$ minus the probability that two independant random walkers are in $\C_k$ and $\C_l$, evaluated at stationarity. A good partition is such that there is a high likelyhood of remaining in the starting community over a given time scale. The definition of the stability of a \textit{clustering} $\P$ follows naturally:
\begin{equation}
	r_t(\P) = \min_{0 \le s \le t} \sum_{i = 1}^{c} [\b R_s]_{ii} = \min_{0 \le s \le t} \trace(\b R_s).
\end{equation}
Note that taking the minimum for all times up to $t$ implies that the stability of the clustering at time $t$ is large only if it is large for all times preceding $t$. This allows to assign a low stability to partitions where there is a high probability of leaving the community and coming back to it later. According to \cite{delvenne2013stability}, this minimisation is unnecessary in most cases and we have $r_t(\P) \approx \trace(\b R_t)$. Nevertheless, taking the minimization ensures maximum generality and allows for example to deal with almost bipartite graphs where $\trace(\b R_s)$ can be oscillatory.
The definitions above stands all for a given partition $\P$. As we are interested in the optimal clustering in the sense of stability, we search the partition that maximize the stability. Clearly, the optimal partition might be different for each Markov time $t$. Computing the optimal partition for each Markov time gives the \textit{stability curve of the graph} :
\begin{equation}
	r_t = \max_{\P} r_t(\P).
\end{equation}
We understand thus how Markov time acts as an intrinsic resolution parameter: as Markov time grows, the number of communities is expected to decrease, since there are more possibilities for a random walker to escape a community when the time window increases. Hence, communities get bigger (or coarser) with Markov time increasing. Interestingly, one can prove that in the case of \textit{undirected} networks, stability at time 1 is equivalent to the well-known \textit{configuration modularity} measure. But this equivalence does not hold for \textit{directed} networks and therefore does not concern the present work.

At this stage, an important remark has to be made about the assumption of ergodicity. The verification of this assumption is often far from being obvious, especially in the case of big undirected networks. The trick in that case is to introduce "à la Google" random teleportations.\footnote{In the original PageRank proposed by S. Brin and L. Page in 1998 (ref. \cite{grin1998anatomy}), this consist essentially in applying a perturbation to the transition probability matrix between web pages in order to ensure that at least one row of the matrix is positive, which implies the convergence of the Power Method. If we note the teleportation probability $\tau$, the perturbation can be interpreted as follows: a web surfer follows a link in his current page with probability $1-\tau$ and jumps to an arbitrary web page with probability $\tau$.} Let $\tau$ be the \textit{teleportation probability}. Then, if a random walker is located on a node with at least one outlink (which is always the case for the networks that we will consider), it follows one of the outlinks with probability $1-\tau$. Otherwise, the node is called a \textit{dangling node} and the random walker is teleported with a uniform probability to another random node. The corresponding perturbation of the transition probability matrix is, in the most general case:
\begin{equation} \label{eq:M_teleport}
	\widetilde{\b M} = (1-\tau)\b M + \frac{1}{N}[(1-\tau)\b d + \tau \b 1]\b 1^{\t},
\end{equation}
where $N$ is the number of nodes, $\b d$ is a binary $N \times 1$ vector whose entries are equal to $1$ if the corresponding node is a dangling node and $0$ otherwise, and $\b 1$ is the $N \times 1$ unity vector. In the case that we will consider in the next section, $\b d$ is the zero vector. This perturbation is known to make the dynamics ergodic, ensuring the existence and uniqueness of the stationary solution $\bs \pi$.

\subsection{Extension to continuous time}
From a general viewpoint, the discrete process can be interpreted as an approximation of its continuous counterpart : whereas the state of the discrete-time random walker can only change at unit-time intervals, the continuous-time random walkers undergoes a waiting time between each change of state which is itself a random variable. More precisely, it is a continuous memoryless random variable distributed exponentially. Obviously, the transition probabilities from one node to the other are the same for both discrete- and continuous-time processes, only the time at which the jump occurs may vary. The continuous-time process corresponding to \eqref{eq:discreteMP} is governed by the following dynamics :
\begin{equation} \label{eq:continuousMP_general}
    	\dot{\b p} = \b p \diag\left\{\bs \lambda(\b k)\right\} \b K^{-1} \b A - \b p \diag\left\{\bs \lambda(\b k)\right\} = -\b p \b L,
\end{equation}
where $\lambda_i(\b k)$ is the rate at which random walkers leave node $i$, and $\b L = \diag\{\bs \lambda(\b k)\}[-\b K^{-1} \b A + \b I]$. Two particular cases of this process are implemented by the stability software and are thus examined here, depending on the choice of $\bs \lambda(\b k)$ : the so-called \textit{normalised Laplacian dynamics} and \textit{standard (combinatorial) Laplacian dynamics}. Their names comes from the similarity that arise between $\b L$ and the normalied/standard Laplacian matrix. Each of those two dynamics represent best different physical processes. The former correspond to the choice $\bs \lambda_{norm}(\b k) = \b 1$. Hence, the expected waiting time is $1$ at every node, and $\b L = -\b K^{-1} \b A + \b I = -\b M + \b I$. The latter corresponds to $\bs \lambda_{combi}(\b k) = \b k/\langle \b k \rangle$. In that case, $\b L = (-\b A + \b K)/\langle \b k \rangle$ and the average waiting time at node $i$ is $\langle \b k \rangle/k_i$. Hence, the expected waiting time at a given node is smaller (resp. larger) than $1$ if the total weight of the outgoing edges from that node is larger (resp. smaller) than the average total weight of the outgoing edges on the network. However, the expected waiting time over the whole network is $\langle \langle \b k \rangle/\b k \rangle = 1$. The corresponding governing equations are respectively 
\begin{equation} \label{eq:continuousMP_norm}
	\dot{\b p} = \b p \b K^{-1} \b A - \b p = \b p \b M - \b p
\end{equation}
for the normalized Laplacian and
\begin{equation} \label{eq:continuousMP_combi}
    	\dot{\b p} = \b p \frac{\b A}{\langle \b k \rangle} - \b p\frac{\b K}{\langle \b k \rangle}
\end{equation}
for the combinatorial Laplacian.

The clustered autocovariance matrix for partition $\P$ at time $t$ is easily generalised to 
\begin{equation}
	\b R(t;\P) = \b H_{\P}^{\t}(\b \Pi\b P(t) - \bs \pi^{\t}\bs \pi)\b H_{\P},
\end{equation}
where $\b P(t)$ is the the transition matrix of the process at time $t$: $\b P(t) = \Exp^{-t\b L}$. The continuous-time definition of the stability of a partition $\P$ follows almost straightforwardly :
\begin{equation}
	r(t;\P) = \trace \left[ \b R(t; \P) \right].
\end{equation}
Notice that it is not necessary to minimise over the time interval $[0,t]$ : indeed, it can be shown that $\trace \left[ \b R(t;\P) \right]$ is monotonically decreasing with time. The interpretation in terms of a random walk is similar to the discrete case : let $P(\C,t)$ be the probability that a random walker is in community $\C$ at time $t$ if it was initially in $\C$, when the system is at stationarity. Discounting the probability of such an event to take place by chance at stationarity and summing over all communities of $\P$ leads to the definition of the stability of the partition $\P$ :
\begin{equation} \label{eq:generalstability}
	r(t;\P) = \sum_{\C \in \P} P(\C,t) - P(\C,\infty).
\end{equation}
By ergodicity, the memory of the initial condition is lost at infinity and $P(\C,\infty)$ is thus equal to the probability that two independant walkers are in $\C$ at stationarity. Equation \eqref{eq:generalstability} tells us that only the communities in which a random walker is likely to stay brings a positive contribution to stability, where \textit{likely to stay} means that the probability for a walker to be in its initial community at time $t$ is larger than the probability of that event occuring by chance at stationarity. The stability curve of the graph can now be expressed as a continuous function of $t$ :
\begin{equation}
	r(t) = \max_{\P} r(t;\P).
\end{equation}


\subsection{Assessing the robustness of a partition}
We present here two mechanisms commonly used to assess the relevance of a particular partition. One simple way is to consider that a robust partition should not be alterred by a small modification of the quality function. Such a modification could be for example a perturbation of the Markov time $t$ at which the partition has been found. From this point of view, robust partitions correspond to \textit{plateaux} in the stability curve of the graph. In other words, robust partitions should be persistent over a wide interval of Markov time.

\begin{sloppypar} 
The second indicator of the robustness of a partition that we will take into account in this work follows from considering that a robust partition is one that is persistent to small modifications of the optimization algorithm. The central tool to quantify this approach of the robustness of a partition is the \textit{normalized variation of information} \cite{meilua2007comparing}, which is a popular way to compare two partitions. Let $p(\C)$ be the probability for a node to be in community $\C$, i.e. $p(\C) = n_\C/N$ where $n_\C$ is the number of nodes in community $\C$. The variation of information between partitions $\P_1$ and $\P_2$ is defined by :
\begin{equation} \label{eq:clustering_VI}
	\VI(\P_1,\P_2) := \frac{H(\P_1,\P_2)-H(\P_1)-H(\P_2)}{\log (N)} = \frac{H(\P_1|\P_2)+H(\P_2|\P_1)}{\log (N)},
\end{equation}
where $\log(N)$ is a normalization factor; $H(\P) = -\sum_{\C} p(\C) \log[p(\C)]$ is the Shannon entropy; $H(\P_1,\P_2)$ is the Shannon entropy of the joint probability $p(\C_1,\C_2)$ that a node belongs to both a community $\C_1$ of $\P_1$ and a community $\C_2$ of $\P_2$. This yields $p(\C_1,\C_2) = n_{\C_1 \cap\, \C_2}/N$, and $H(\P_1,\P_2) = -\sum_{\C_1 \in \P_1} \sum_{\C_2 \in \P_2} p(\C_1,\C_2) \log[p(\C_1,\C_2)]$; and $H(\P_1|\P_2)$ is the conditional Shannon entropy of partition $\P_1$ given $\P_2$, which is defined in a standard way from the joint distribution: $p(\C_1|\C_2) = p(\C_1,\C_2)/p(\C_2) = n_{\C_1\cap\, \C_2}/n_{\C_2}$, and the expression of $H(\P_1|\P_2)$ follows straightforwardly. The latter can be interpreted as the additional information needed to describe $\P_1$ once $\P_2$ is known. This measure of the difference bewteen two partition is then used as follows: for each Markov time, an ensemble of Louvain optimisations of stability are performed, starting from different random initial node ordering. Remember that the problem being $\mathcal{NP}$-hard, we rely on a heuristic algorithm --- the Louvain method --- that finds a good partition for a given Markov time, but not necessarily the optimal partition. Hence the partition found may differ if a different initial condition is provided. The normalized variation of information allows then to quantify how different the optimised partitions are. Therefore, a low variation of information indicates optimised partitions that are very similar to each others, hence that a small modification of the algorithm barely alter the partition. From the point of view of the field of dynamical system, robust partitions have thus an attractor with a large basin of attraction for the optimisation method. 
\end{sloppypar}


%-------------------------------------------CLUSTERING OVERTURNER-----------------------------------------------%
\section{Clustering of the overturner problem}
% 1. Expliquer ce qu'on va faire
% 2. Décomposition du domaine en boxes, on cherche ce que donne le clustering sur ces boxes.
% 3. Résultats pour nboxy = 15, nboxz = 10 (et expliquer que ces choix permettent que y0 et z0 correspondent à des frontières de box)

This section presents the results of applying a community detection algorithm based on the stability measure on the overturner problem. First, we explain how the method is applied and then we present the results for a given set of data's.

%-----------------------DESCRIPTION OF THE METHOD---------------------------------%
\subsection{Description of the method}
In order to apply a clustering algorithm on the overturner problem, we have to define how the model can be considered as a graph. To this end, the domain is decomposed into $\nby \times \nbz$ boxes. We note $N_{box} = \nby\nbz$ the total number of boxes. Figure \ref{fig:box_scheme} represents an example of such a domain decomposition with $\nby = 15$ and $\nbz = 10$. For any time $T$, the corresponding directed graph is build as follows : each node represents a box, and the weight of the edge between nodes $i$ and $j$ is the probability $m^T_{ij}$ that a particle ends up in box $j$ after a time $T$ if it was initially in box $i$. If $m^T_{ij} = 0$, one can equivalently consider that there is no edge between nodes $i$ and $j$. Since the problem is stationnary, $m^T_{ij}$ depends only on the time range $T$, not on the initial time. Hence, the initial time can indifferently be considered as being zero. The adjacency matrix $\b M(T)$ of the graph is build from the weights $m^T_{ij}$ : $[\b M(T)]_{ij} = m^T_{ij}$. For any time $T$, $\b M(T)$ is row-stochastic, i.e. $\b M(T)\b 1 = \b 1$, where $\b 1$ is the $N_{box}$-dimensional unit column vector.
\begin{figure}[h!]
	\centering
	\input{fig/clusters/box_scheme}
	\caption{Illustration of the decomposition of the domain into boxes with $\nby = 15$ and $\nbz = 10$.}
	\label{fig:box_scheme}
\end{figure}

To estimate the probabilities $m^T_{ij}$, the program is runned for a time $T$ with each box containing initially $J$ uniformly distributed particles. $m^T_{ij}$ is then numerically estimated as the number of particles $p_{ij}$ having started in box $i$ and ending up in box $j$, divided by $J$. This \textit{box counting} method has been extensively used to estimate the concentration in studies using random walk modeling, see e.g. \cite{riddle1998specification}. Nevertheless, this method suffers some drawbacks; the most important of them are pointed in \cite{spivakovskaya2007lagrangian}. The estimated transition probability depends on the choice of the boxes, in particular of their size and their center. Moreover, the number of boxes cannot be chosen to be too large; otherwise the estimated concentration tends to become very irregular or noisy. Finally, the resolution of the estimated concentration is limited to the size of the boxes, as it cannot be described in a box more precisely than a constant. But it is the perfect method for our problem since the volume average over such boxes (the nodes) is precisely what we want. Note however that other methods exist for estimating the concentration that might be better suited for other studies. For example, the \textit{kernel estimation} method allows to reduce drastically the number of particles, and does not suffer from the resolution limit inherent to the box counting method. This method is briefly presented in \cite{spivakovskaya2007lagrangian}. Classical references are \cite{silverman1986density} and \cite{wand1995kernel}.


%-------------------------USE OF THE TOOLBOX----------------------------%
\subsection{Use of the stability software}
% \newcommand\localFontSize@mlpr{10}
We present here briefly how the \textit{PartitionStability} software is used to compute the partitions. Every concept appearing here has been presented in section \ref{sec:stability}. The \mtlb{stability} function is simply called as follows : \vspace{-.2cm}
\begin{center}
	\mtlb{[S,N,VI,C] = stability(M,Markov_T,'directed','plot','teleport',0.01);}
\end{center} %style = Matlab-bw for black and white
Here, \mtlb{M} is the matrix $\b M(T)$ at the desired time $T$; \mtlb{Markov_T} is the vector containing every Markov times at which the optimal stability partition has to be computed; the \mtlb{'directed'} option specifies that we consider a directed graph; \mtlb{'plot'} ask the program to plot the stability, number of communities and variation of information as a function of the Markov time; and \mtlb{'teleport',0.01} allows to specify the value of the teleportation probability $\tau$ to $0.01$, the default value being $0.15$. this choice is motivated by the fact that we believe the graph to be ergodic, even if we cannot prove it. Note that the program allows to choose which type of laplacian should be used to calculate the stability. However, the question does not arise here since both laplacians are equivalent in our case. Indeed, the total outgoing weight is the same at every node and is precisely equal to the number of particles $J$ released in each box. Hence, $k_i = J$ for every node $i$ and $\langle \b k \rangle = 1$, so that $\bs \lambda_{combi}(\b k) = \b k/ \langle \b k \rangle = \b 1 = \bs \lambda_{norm}(\b k)$. We let thus the program run with the default normalized Laplacian, since it does not make any difference in our case. The output arguments \mtlb{S}, \mtlb{N}, \mtlb{VI} and \mtlb{C} contain respectively the stability, the number of communities, the variation of information, and the optimal partition for each Markov time contained in \mtlb{Markov_T}. If the latter is of size $n$, then \mtlb{S}, \mtlb{N} and \mtlb{VI} are $n$-dimensional vectors and \mtlb{C} is a $N_{box} \times n$ matrix. At the $j$th Markov time, communities are labeled by consecutive integers between $0$ and \mtlb{N(j)}$-1$ such that \mtlb{C(i,j)} $= k$ means that node $i$ belongs to community $k$ at Markov time \mtlb{Markov_T(j)}.  



%--------------------------RESULTS--------------------------------------%
\subsection{Results}