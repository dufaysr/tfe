%!TEX root = ../tfe.tex
\chapter{Clustering}
\section{The stability criterion for graph communities}
This section is devoted to the explanation of 
The partition of a graph into communities (or clusters) as been widely studies those last two decades. Clustering is indeed a great tool to gain insight into the underlying structure of a system represented by a network. In some cases, one can even build a simplified functional description base on the clusters. Many partitioning methods have been proposed, each relying on a particular measure to quantify the quality of a community structure. Such methods include normalized cut, ($\alpha$,$\epsilon$) clustering or modularity and its variants and extensions. See for instance \cite{fortunato2010community} for a 2010 survey. In this work, we choose the stability approach, initially presented in \cite{delvenne2010stability} and further expended in \cite{lambiotte2009laplacian} and \cite{delvenne2013stability}. The stability method presents a number of advantages. First, it does not require the number of communities to be specified beforehand, ensuring a natural partitioning of the graph. Second, it is flexible in the sense that it does not seek a \textit{unique} optimal partition. Instead, it reveals several community structures, each appearing to be the most relevant at particular values of the Markov time. The latter acts as an intrinsic resolution parameter, as will be explained shortly. Finally, it is probably the most unifying approach since many of the standard partitioning measures find an interpretation through the stability framework.

\subsection{Discrete-time stability as an autocovorariance}
The stability criterion is based on the two-way relationship between graphs and Markov chains: On one hand, any graph has an associated Markov chain where the states are the nodes of the graph and the transitions probabilities between states are given by the weights of the edges. On the other hand, any Markov chain can be represented by a graph whose edges are weighted according to the transition probabilities. Concretely, consider a graph of $N$ nodes whose $N \times N$ weighted adjacency matrix is denoted $\b A$. Let $\b k = \b A \b 1$; $k_i$ is thus the total weight of the outgoing edges from node $i$. Let $\b K = \mathrm{diag}(\b k)$. Then, by normalizing the rows of $\b A$ we get the matrix $\b M = \b K^{-1}\b A$, the transition probability matrix. $\b M$ is row-stochastic and $[\b M]_{ij}$ is the probability to go from node $i$ to node $j$. If $\b p_t$ is the $N \times 1$ probability vector at Markov time $t$, then the dynamics of the discrete-time Markov process are given by :
\begin{equation} \label{eq:discreteMP}
	\b p_{t+1} = \b p \b K^{-1}\b A = \b p_t \b M.  	
\end{equation} 
This Markov perspective provides a dynamical interpretation of the partitioning problem : at a given time scale, natural clusters corresponds to sets of states from which escape is unlikely within that time scale. Hence, the stability measure of the quality of a clustering is based on the statistical properties of a dynamical process taking place on the network. 

Consider a finite-state Markov process $\M$ and a partition $\P$. Suppose that $\M$ is ergodic, i.e. that it is possible to go from every state to every state and that the Markov process is aperiodic. Note that this implies that any initial state will asymptotically reach the same stationary solution. Let $P(\C,t)$ be the probability that a random walker is in community $\C$ at that $t$ if it was initially in $\C$, when the system is at stationarity. Discounting the probability of such an event to take place by chance at stationarity and summing over all communities of $\P$ leads to the definition of the stability of the partition $\P$ :
\begin{equation} \label{eq:generalstability}
	r(t;\P) = \min_{0 \le s \le t} \sum_{\C \in \P} P(\C,s) - P(\C,\infty).
\end{equation}
By ergodicity, the memory of the initial condition is lost at infinity and $P(\C,\infty)$ is thus equal to the probability that two independant walkers are in $\C$ at stationarity. Equation \eqref{eq:generalstability} tells us that only the communities in which a random walker is likely to stay brings a positive contribution to stability, where \textit{likely to stay} means that the probability for a walker to be in its initial community at time $t$ is larger than the probability of that event occuring by chance at stationarity. Note that taking the minimum for all times up to $t$ implies that the stability of the clustering at time $t$ is large only if it is large for all times preceding $t$. This allows to assign a low stability to partitions where there is a high probability of leaving the community and coming back to it later. 

Let us developp definition \eqref{eq:generalstability} to express it in matrix form. We consider a discrete-time Markov process, or Markov chain. Let $\b M$ be the transition probability matrix of a finite state Markov chain, namely that $[\b M]_{ij}$ is the probability of going to state $j$ at time $t+1$ if we are in state $i$ at time $t$. Let $\bs \pi$ be the stationnary distribution of the ergodic Markov chain, given by $\bs \pi = \bs \pi  \b M$, and $\b \Pi = \rm{diag}(\bs \pi)$. Finally, let $\b H_{\P}$ be the indicator matrix of the partition $\P$. If $N$ is the number of states and $c$ the number of communities in $\P$, $\b H_{\P}$ is a binary $N \times c$ matrix such that 
\begin{equation}
	[\b H_{\P}]_{ik} = 
	\begin{cases}
		1       & \quad \mbox{if node $i$ is in community $k$},\\
	    0  & \quad \text{otherwise}.\\
	\end{cases}
\end{equation}
Using those notations, the \textit{clustered autocovariance matrix} at time $t$ is defined as
\begin{equation}
	\b R_t = \b H_{\P}^{\t}(\b \Pi\b M^t - \bs \pi^{\t}\bs \pi)\b H_{\P},
\end{equation}
where $^\t$ is the transposed sign and $\b M^t$ is $\b M$ at the power $t$. Finally, the stability of the \textit{clustering} $\P$ is expressed as
\begin{equation}
	r(t;\P) = \min_{0 \le s \le t} \sum_{i = 1}^{c} [\b R_s]_{ii} = \min_{0 \le s \le t} \rm{trace}(\b R_s).
\end{equation}
The definitions above stands all for a given partition $\P$. As we are interested in the optimal clustering in the sense of stability, we search the partition that maximize the stability. Clearly, the optimal partition might be different for each different Markov time $t$. Computing the optimal partition for each Markov time $t$ gives the \textit{stability curve of the graph} :
\begin{equation}
	r(t) = \max_{\P} r(t;\P).
\end{equation}
We understand thus how Markov time acts as an intrinsic resolution parameter : as Markov time grows, the number of communities decreases. This is quite intuitive since there are more possibilities for a random walker to escape a community, when the time scale increases. Hence, communities get bigger or coarser with Markov time increasing. Interestingly, one can prove that in the case of \textit{undirected networks}, stability at time 1 is equivalent to the well-known configuration modularity measure. But this equivalence does not hold for directed networks and therefore does not concern the present work.

At this stage, an important remark has to be made about the assumption of ergodicity. The verification of this assumption is often far from being obvious, especially in the case of big undirected networks. The trick in that case is to introduce "à la Google" random teleportations.\footnote{In the original PageRank proposed by S. Brin and L. Page in 1998 (ref. \cite{grin1998anatomy}), this consist essentially in applying a perturbation to the transition probability matrix between web pages in order to ensure that at least one row of the matrix is positive, which implies the convergence of the Power Method. If we note the teleportation probability $\tau$, the perturbation can be interpreted as follows : a web surfer follows a link in his current page with probability $1-\tau$ and jumps to an arbitrary web page with probability $\tau$.} Let $\tau$ be the \textit{teleportation probability}. Then, if a random walker is located on a node with at least one outlink (which is always the case for the network that we consider), it follows one of the outlinks with probability $1-\tau$. Otherwise, the node is called a \textit{dangling node} and the random walker is teleported with a uniform probability to another random node. The corresponding perturbation of the transition probability matrix is, in the most general case :
\begin{equation} \label{eq:M_teleport}
	\widetilde{\b M} = (1-\tau)\b M + \frac{1}{N}[(1-\tau)\b d + \tau \b 1]\b 1^{\t},
\end{equation}
where $N$ is the number of nodes, $\b d$ is a binary $N \times 1$ vector whose entries are equal to $1$ if the corresponding node is a dangling node and $0$ otherwise, and $\b 1$ is the $N \times 1$ unity vector. In the case that we will consider in the next section, $\b d$ is the zero vector. This perturbation is known to make the dynamics ergodic, ensuring the existence and uniqueness of the stationary solution $\bs \pi$.


\subsection{Extension to continuous time}
From a general viewpoint, the discrete process can be interpreted as an approximation of its continuous counterpart : whereas the state of the discrete-time random walker can only change at unit-time intervals, the continuous-time random walkers undergoes a waiting time between each change of state which is itself a random variable. More precisely, it is a continuous memoryless random variable distributed exponentially with unit expectation. Obviously, the transition probabilities from one node to the other are the same for both processes, only the time at which the jump occurs may vary. The continuous-time process corresonding to \eqref{eq:discreteMP} is governed by the so-called \textit{Kolmogorov equation} :
\begin{equation} \label{eq:continuousMP_general}
    	\dot{\b p} = \b p \diag\left\{\bs \lambda(\b k)\right\} \b K^{-1} \b A - \diag\left\{\bs \lambda(\b k)\right\} \b p,
\end{equation}
where $\lambda_i(\b k)$ is the rate at which random walkers leave node $i$. Two particular cases of this process are implemented by the stability software : the \textit{normalised Laplacian dynamics} and the \textit{standard (combinatorial) Laplacian dynamics}. The former correspond to the choice $\bs \lambda(\b k) = \b 1$. Hence, the expected waiting time is 1 at every node. The latter corresponds to $\bs \lambda(\b k) = \b k/\langle \b k \rangle$. In that case, the average waiting time at node $i$ is $\langle \b k \rangle/k_i$. Hence, the expected waiting time at a given node is smaller (resp. larger) than $1$ if the total weight of the outgoing edges from that node $i$ is larger (resp. smaller) than the average total weight of the outgoing edges on the network. However, the expected waiting time over the whole network is $\langle \langle \b k \rangle/\b k \rangle = 1$. The corresponding governing equations are respectively 
\begin{equation} \label{eq:continuousMP_norm}
	\dot{\b p} = \b p \b K^{-1} \b A - \b p = \b p \b M - \b p
\end{equation}
for the normalized Laplacian and
\begin{equation} \label{eq:continuousMP_combi}
    	\dot{\b p} = \b p \frac{\b A}{\langle \b k \rangle} - \frac{\b K}{\langle \b k \rangle} \b p
\end{equation}
for the combinatorial Laplacian.

\subsection{Assessing the robustness of a partition}
We present here two mechanism commonly used to assess the relevance of a particular partition. One simple way is to consider that a robust partition should not be alterred by a small modification of the quality function. Such a modification could be for example a perturbation of the Markov time $t$ at which the partition has been found. From this point of view, robust partitions correspond to \textit{plateaux} in the stability curve of the graph. In other words, robust partitions should be persistent over a wide interval of Markov time.

\begin{sloppypar} 
The second indicator of the robustness of a partition that we will take into account in this work follows from considering that a robust partition is one that is persistent to small modifications of the optimization algorithm. The central tool to quantify this approach of the robustness of a partition is the \textit{normalized variation of information} \cite{meilua2007comparing}. This is a popular way to compare two partitions. Let $p(\C)$ be the probability for a node to be in community $\C$, i.e. $p(\C) = n_\C/N$ where $n_\C$ is the number of nodes in community $\C$. The variation of information between partitions $\P_1$ and $\P_2$ is defined by :
\begin{equation} \label{eq:clustering_VI}
	\VI(\P_1,\P_2) := \frac{H(\P_1,\P_2)-H(\P_1)-H(\P_2)}{\log (N)} = \frac{H(\P_1|\P_2)+H(\P_2|\P_1)}{\log (N)},
\end{equation}
where $\log(N)$ is a normalization factor; $H(\P) = -\sum_{\C} p(\C) \log[p(\C)]$ is the Shannon entropy; $H(\P_1,\P_2)$ is the Shannon entropy of the joint probability $p(\C_1,\C_2)$ that a node belongs to both a community $\C_1$ of $\P_1$ and a community $\C_2$ of $\P_2$. This yields $p(\C_1,\C_2) = n_{\C_1 \cap\, \C_2}/N$, and $H(\P_1,\P_2) = -\sum_{\C_1 \in \P_1} \sum_{\C_2 \in \P_2} p(\C_1,\C_2) \log[p(\C_1,\C_2)]$; and $H(\P_1|\P_2)$ is the conditional Shannon entropy of partition $\P_1$ given $\P_2$, which is defined in a standard way from the joint distribution: $p(\C_1|\C_2) = p(\C_1,\C_2)/p(\C_2) = n_{\C_1\cap\, \C_2}/n_{\C_2}$, and the expression of $H(\P_1|\P_2)$ follows straightforwardly. The latter can be interpreted as the additional information needed to describe $\P_1$ once $\P_2$ is known. This measure of the difference bewteen two partition is then used as follows: for each Markov time, an ensemble of Louvain optimisations of stability are performed, starting from different random initial node ordering. Remember that the problem being $\mathcal{NP}$-hard, we rely on a heuristic algorithm --- the Louvain method --- that finds a good partition for a given Markov time, but not necessarily the optimal partition. Hence the partition found may differ if a different initial condition is provided. The normalized variation of information allows then to quantify how different the optimised partitions are. Therefore, a low variation of information indicates optimised partitions that are very similar to each others, hence that a small modification of the algorithm barely alter the partition. From the point of view of the field of dynamical system, robust partitions have thus an attractor with a large basin of attraction for the optimisation method. 
\end{sloppypar}

\subsection{Software}
In order to compute stability partitions in the next of this work, we make use of Michael Schaub's free software \textit{PartitionStability}. This C++ implementation of the stability method with a \matlab interface is available at \url{https://github.com/michaelschaub/PartitionStability}. It relies on the Louvain algorithm \cite{blondel2008fast} to optimize the stability quality function. This heuristic algorithm has been initially developed for modularity optimisation. However one can show that stability can be written as the \textit{modularity} of a time-dependent network evolving under the Markov process \cite{lambiotte2009laplacian}. Hence, the Louvain method can almost straightforwardly be applied to stability optimisation.


%-------------------------------------------CLUSTERING OVERTURNER-----------------------------------------------%
\section{Clustering of the overturner problem}
% 1. Expliquer ce qu'on va faire
% 2. Décomposition du domaine en boxes, on cherche ce que donne le clustering sur ces boxes.
% 3. Résultats pour nboxy = 15, nboxz = 10 (et expliquer que ces choix permettent que y0 et z0 correspondent à des frontières de box)

This section presents the results of applying a community-detection algorithm on the overturner problem. First, we explain how the method is applied and then we present the results for a given set of data's.

%-----------------------DESCRIPTION OF THE METHOD---------------------------------%
\subsection{Description of the method}
In order to apply a clustering algorithm on the overturner problem, we have to define how the model can be considered as a graph. To this end, the domain is decomposed into $\nby \times \nbz$ boxes. Figure \ref{fig:box_scheme} represents an example of such a domain decomposition with $\nby = 15$ and $\nbz = 10$. For any time $T$, the corresponding directed graph is build as follows : each node represents a box, and there is an edges between nodes $i$ and $j$ if the probability $m^T_{ij}$ that a particle ends up in box $j$ after a time $T$ if it started in box $i$ is nonzero. The weight of that edge is then $m^T_{ij}$. Since the problem is stationnary, $m^T_{ij}$ depends only on the time range $T$, not on the initial time. Hence, the initial time can indifferently be considered as being zero. The adjacency matrix $\b M(T)$ of the graph is build from the weights $m^T_{ij}$ : $[\b M(T)]_{ij} = m^T_{ij}$. For any time $T$, $\b M(T)$ is row-stochastic :
\begin{equation}
	\b M(T) \cdot \b 1 = \b 1,
\end{equation}
where $\b 1$ is the unit column vector of size $\nby\nbz$.
\begin{figure}[h!]
	\centering
	\input{fig/clusters/box_scheme}
	\caption{Illustration of the decomposition of the domain into boxes with $\nby = 15$ and $\nbz = 10$.}
	\label{fig:box_scheme}
\end{figure}

To estimate the probabilities $m^T_{ij}$, the program is runned for a time $T$ with each box containing initially $J$ uniformly distributed particles. $m^T_{ij}$ is then numerically estimated as the number of particles $p_{ij}$ having started in box $i$ and ending up in box $j$, divided by $J$. This \textit{box counting} method has been extensively used to estimate the concentration in studies using random walk modelling, see e.g. \cite{riddle1998specification}. As pointed in \cite{spivakovskaya2007lagrangian}, this method suffers some drawbacks. The estimated transition probability depends on the choice of the boxes, in particular of their size and their center. Moreover, the number of boxes cannot be chosen to be too large; otherwise the estimated concentration tends to become very irregular or noisy. Finally, the resolution of the estimated concentration is limited to the size of the boxes, as it cannot be described in a box more precisely than a constant. But it is the perfect method for our problem since the volume average over such boxes (the nodes) is precisely what we want. Note however that other methods exist for estimating the concentration that might be better suited for other studies. For example, the \textit{kernel estimation} method allows to reduce drastically the number of particles, and does not suffer from the resolution limit inherent to the box counting method. This method is briefly presented in \cite{spivakovskaya2007lagrangian}. Classical references are \cite{silverman1986density} and \cite{wand1995kernel}.

%--------------------------RESULTS--------------------------------------%
\subsection{Results}